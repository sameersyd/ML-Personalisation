{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizeOfSets = 500\n",
    "val = [None] * 4000 # Keep value (sizeOfSets * no. of categories)\n",
    "sizeOfTweetContent = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['airlines', 'celebrities', 'colleges', 'fastfood', \n",
    "              'leagues', 'news', 'streamingplatforms', 'techgiants']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputDataInDataframe():\n",
    "    overCount= 0\n",
    "    for i in categories:\n",
    "        direc:str = '/Users/sameernawaz/AnacondaProjects/Datasets/tweets/'+i+'/trainingTextClassification.csv'\n",
    "        with open(direc, 'r') as csv_file:\n",
    "            csv_reader = csv.reader(csv_file)\n",
    "            count = 0\n",
    "            for line in csv_reader:\n",
    "                if len(line[6]) > sizeOfTweetContent:\n",
    "                    val[overCount] = line\n",
    "                    count += 1\n",
    "                    overCount += 1\n",
    "                    if count >= sizeOfSets :\n",
    "                        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDataInDataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(val, columns = ['date', 'username', 'to', 'replies', \n",
    "                                  'retweets', 'favorites', 'text', 'geo', \n",
    "                                  'mentions', 'hashtags', 'id', 'permalink']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once data added in dataframe, Shuffle it\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "# Add a unique id (rec_id) for all tweets\n",
    "df = df.assign(rec_id=np.arange(len(df))).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4000 entries, 0 to 3999\n",
      "Data columns (total 3 columns):\n",
      "rec_id      4000 non-null int64\n",
      "username    4000 non-null object\n",
      "text        4000 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 125.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df[['rec_id', 'username', 'text']]\n",
    "df.dropna(inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "import contractions\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def normalize_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-zA-Z0-9\\s]', '', doc, re.I|re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    doc = contractions.fix(doc)\n",
    "    # tokenize document\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    #filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc\n",
    "\n",
    "normalize_corpus = np.vectorize(normalize_document)\n",
    "\n",
    "norm_corpus = normalize_corpus(list(df['text']))\n",
    "len(norm_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 10013)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract TF-IDF\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf = TfidfVectorizer(ngram_range=(1, 2), min_df=2)\n",
    "tfidf_matrix = tf.fit_transform(norm_corpus)\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3990</th>\n",
       "      <th>3991</th>\n",
       "      <th>3992</th>\n",
       "      <th>3993</th>\n",
       "      <th>3994</th>\n",
       "      <th>3995</th>\n",
       "      <th>3996</th>\n",
       "      <th>3997</th>\n",
       "      <th>3998</th>\n",
       "      <th>3999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011699</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032637</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011887</td>\n",
       "      <td>0.018572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026500</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.54168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4         5     6         7         8     9     \\\n",
       "0   1.0   0.0   0.0   0.0   0.0  0.000000   0.0  0.000000  0.000000   0.0   \n",
       "1   0.0   1.0   0.0   0.0   0.0  0.000000   0.0  0.000000  0.000000   0.0   \n",
       "2   0.0   0.0   1.0   0.0   0.0  0.032637   0.0  0.000000  0.000000   0.0   \n",
       "3   0.0   0.0   0.0   1.0   0.0  0.000000   0.0  0.011887  0.018572   0.0   \n",
       "4   0.0   0.0   0.0   0.0   1.0  0.000000   0.0  0.000000  0.000000   0.0   \n",
       "\n",
       "   ...  3990  3991  3992  3993      3994  3995  3996  3997      3998     3999  \n",
       "0  ...   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0  0.000000  0.00000  \n",
       "1  ...   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0  0.011699  0.00000  \n",
       "2  ...   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0  0.000000  0.00000  \n",
       "3  ...   0.0   0.0   0.0   0.0  0.074035   0.0   0.0   0.0  0.026500  0.00000  \n",
       "4  ...   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0  0.000000  0.54168  \n",
       "\n",
       "[5 rows x 4000 columns]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute Pairwise Document Similarity\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "doc_sim = cosine_similarity(tfidf_matrix)\n",
    "doc_sim_df = pd.DataFrame(doc_sim)\n",
    "doc_sim_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0,    1,    2, ..., 3997, 3998, 3999]), (4000,))"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get list of post IDs\n",
    "\n",
    "posts_list = df['rec_id'].values\n",
    "posts_list, posts_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3997"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_idx = np.where(posts_list == 3997)[0][0]\n",
    "posts_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 1., 0., 0.])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_similarities = doc_sim_df.iloc[posts_idx].values\n",
    "posts_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3997, 3707, 3543,  551, 2176])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get top 5 similar post IDs\n",
    "\n",
    "similar_posts_idxs = np.argsort(-posts_similarities)[1:6]\n",
    "similar_posts_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3285, 3716, 3694, 1054,  263])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_posts = posts_list[similar_movie_idxs]\n",
    "similar_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relevant_posts(postId, posts = posts_list, doc_sims = doc_sim_df):\n",
    "    # find post id\n",
    "    posts_idx = np.where(posts == postId)[0][0]\n",
    "    # get posts similarities\n",
    "    posts_similarities = doc_sims.iloc[posts_idx].values\n",
    "    # get top 5 similar post IDs\n",
    "    similar_posts_idxs = np.argsort(-posts_similarities)[1:6]\n",
    "    # get top 5 posts\n",
    "    similar_posts = posts[similar_posts_idxs]\n",
    "    # return the top 5 posts\n",
    "    return similar_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lawsuit filed in federal court accuses Education Dept. and America's federal consumer watchdog agency of abandoning its authority to oversee companies that service federal student loans.\n",
      "\n",
      "\n",
      "=> NEW: Top Democratic senators revealed a new online privacy bill Tuesday that could mark a milestone in the lengthy push for a federal privacy law and would strengthen the Federal Trade Commission’s ability to enforce digital privacy protections.\n",
      "=> A collaborative research project on estuaries led by the @GrahamInstitute and @UMSEAS has been awarded a $20M federal agreement to study the effects of climate change and land use on 29 coastal reserves. http://myumi.ch/7ZZ9X\n",
      "=> A team of @UMengineering researchers will lead a federal, multi-institute project in developing synthetic neurons—the first challenge in creating synthetic cells—and re-creating the communication process that occurs throughout the body’s nervous system. http://myumi.ch/88Grr\n",
      "=> As the federal government aims to implement new acts and measures to restrict the use of harmful chemicals, experts agree that greater measures should be taken to protect vulnerable populations. http://myumi.ch/erGgR\n",
      "=> A federal program that aims to improve patient safety across the nation by punishing hospitals with high rates of hospital-acquired conditions may not be as effective as initially thought, according to a @UMichSPH researcher. http://myumi.ch/Yyz5Z\n"
     ]
    }
   ],
   "source": [
    "post_id = 3265\n",
    "\n",
    "print((df.loc[df['rec_id'] == post_id]['text']).values[0])\n",
    "print('\\n')\n",
    "for i in relevant_posts(postId = post_id, posts = posts_list, doc_sims = doc_sim_df):\n",
    "    print(\"=>\",(df.loc[df['rec_id'] == i]['text']).values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
