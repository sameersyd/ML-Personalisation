{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['airlines', 'celebrities', 'colleges', 'fastfood', \n",
    "              'leagues', 'news', 'streamingplatforms', 'techgiants']\n",
    "\n",
    "subCategories = [['output_AmericanAir', 'output_Delta', 'output_easyJet', 'output_JetBlue'], \n",
    "                 ['output_amyschumer', 'output_ArianaGrande', 'output_chrissyteigen', 'output_jimmyfallon'], \n",
    "                 ['output_DukeU', 'output_Harvard', 'output_MIT', 'output_Princeton'], \n",
    "                 ['output_Arbys', 'output_BurgerKing', 'output_ChickFilA', 'output_ChipotleTweets'], \n",
    "                 ['output_IPL', 'output_MLB', 'output_MLS', 'output_NBA'], \n",
    "                 ['output_BBCWorld', 'output_CNN', 'output_FoxNews', 'output_HuffPost'], \n",
    "                 ['output_ABCNetwork', 'output_AppleMusic', 'output_disneyplus', 'output_HBO'], \n",
    "                 ['output_amazon', 'output_facebook', 'output_fitbit', 'output_IBM']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800\n"
     ]
    }
   ],
   "source": [
    "sizeOfSets = 400\n",
    "\n",
    "categCount = 0\n",
    "for i in range(len(categories)):\n",
    "    for j in subCategories[i]:\n",
    "        categCount += 1\n",
    "        \n",
    "categCount *= sizeOfSets\n",
    "\n",
    "val = [None] * categCount # Keep value (sizeOfSets * no. of categories)\n",
    "sizeOfTweetContent = 75\n",
    "\n",
    "print(len(val)) # No. Of Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputDataInDataframe():\n",
    "    overCount= 0\n",
    "    for i in range(len(categories)):\n",
    "        for j in subCategories[i]:\n",
    "            direc:str = '/Users/sameernawaz/AnacondaProjects/Datasets/tweets/'+categories[i]+'/'+j+'.csv'\n",
    "            with open(direc, 'r') as csv_file:\n",
    "                csv_reader = csv.reader(csv_file)\n",
    "                count = 0\n",
    "                for line in csv_reader:\n",
    "                    if len(line[6]) > sizeOfTweetContent:\n",
    "                        val[overCount] = line\n",
    "                        count += 1\n",
    "                        overCount += 1\n",
    "                        if count >= sizeOfSets :\n",
    "                            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDataInDataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(val, columns = ['date', 'username', 'to', 'replies', \n",
    "                                  'retweets', 'favorites', 'text', 'geo', \n",
    "                                  'mentions', 'hashtags', 'id', 'permalink']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once data added in dataframe, Shuffle it\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "# Add a unique id (rec_id) for all tweets\n",
    "df = df.assign(rec_id=np.arange(len(df))).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12800 entries, 0 to 12799\n",
      "Data columns (total 3 columns):\n",
      "rec_id      12800 non-null int64\n",
      "username    12800 non-null object\n",
      "text        12800 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 400.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df[['rec_id', 'username', 'text']]\n",
    "df.dropna(inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12800"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "import contractions\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def normalize_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-zA-Z0-9\\s]', '', doc, re.I|re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    doc = contractions.fix(doc)\n",
    "    # tokenize document\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    #filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc\n",
    "\n",
    "normalize_corpus = np.vectorize(normalize_document)\n",
    "\n",
    "norm_corpus = normalize_corpus(list(df['text']))\n",
    "len(norm_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12800, 25271)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract TF-IDF\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf = TfidfVectorizer(ngram_range=(1, 2), min_df=2)\n",
    "tfidf_matrix = tf.fit_transform(norm_corpus)\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>12790</th>\n",
       "      <th>12791</th>\n",
       "      <th>12792</th>\n",
       "      <th>12793</th>\n",
       "      <th>12794</th>\n",
       "      <th>12795</th>\n",
       "      <th>12796</th>\n",
       "      <th>12797</th>\n",
       "      <th>12798</th>\n",
       "      <th>12799</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045639</td>\n",
       "      <td>0.016082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028028</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024559</td>\n",
       "      <td>0.016572</td>\n",
       "      <td>0.017659</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 12800 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3      4         5         6      7         8      \\\n",
       "0    1.0    0.0    0.0    0.0    0.0  0.000000  0.000000    0.0  0.000000   \n",
       "1    0.0    1.0    0.0    0.0    0.0  0.000000  0.000000    0.0  0.000000   \n",
       "2    0.0    0.0    1.0    0.0    0.0  0.045639  0.016082    0.0  0.028028   \n",
       "3    0.0    0.0    0.0    1.0    0.0  0.000000  0.035562    0.0  0.019943   \n",
       "4    0.0    0.0    0.0    0.0    1.0  0.000000  0.000000    0.0  0.000000   \n",
       "\n",
       "      9      ...  12790  12791  12792  12793  12794  12795     12796  \\\n",
       "0  0.000000  ...    0.0    0.0    0.0    0.0    0.0    0.0  0.000000   \n",
       "1  0.000000  ...    0.0    0.0    0.0    0.0    0.0    0.0  0.000000   \n",
       "2  0.000000  ...    0.0    0.0    0.0    0.0    0.0    0.0  0.024559   \n",
       "3  0.000000  ...    0.0    0.0    0.0    0.0    0.0    0.0  0.000000   \n",
       "4  0.089032  ...    0.0    0.0    0.0    0.0    0.0    0.0  0.000000   \n",
       "\n",
       "      12797     12798     12799  \n",
       "0  0.000000  0.000000  0.028164  \n",
       "1  0.000000  0.000000  0.000000  \n",
       "2  0.016572  0.017659  0.000000  \n",
       "3  0.000000  0.000000  0.000000  \n",
       "4  0.000000  0.000000  0.000000  \n",
       "\n",
       "[5 rows x 12800 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute Pairwise Document Similarity\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "doc_sim = cosine_similarity(tfidf_matrix)\n",
    "doc_sim_df = pd.DataFrame(doc_sim)\n",
    "doc_sim_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    0,     1,     2, ..., 12797, 12798, 12799]), (12800,))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get list of post IDs\n",
    "\n",
    "posts_list = df['rec_id'].values\n",
    "posts_list, posts_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3997"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_idx = np.where(posts_list == 3997)[0][0]\n",
    "posts_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.10489771, ..., 0.01281918, 0.01366   ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_similarities = doc_sim_df.iloc[posts_idx].values\n",
    "posts_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8745, 12431, 10785,  6713,  8249])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get top 5 similar post IDs\n",
    "\n",
    "similar_posts_idxs = np.argsort(-posts_similarities)[1:6]\n",
    "similar_posts_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8745, 12431, 10785,  6713,  8249])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_posts = posts_list[similar_posts_idxs]\n",
    "similar_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relevant_posts(postId, posts = posts_list, doc_sims = doc_sim_df):\n",
    "    # find post id\n",
    "    posts_idx = np.where(posts == postId)[0][0]\n",
    "    # get posts similarities\n",
    "    posts_similarities = doc_sims.iloc[posts_idx].values\n",
    "    # get top 5 similar post IDs\n",
    "    similar_posts_idxs = np.argsort(-posts_similarities)[1:6]\n",
    "    # get top 5 posts\n",
    "    similar_posts = posts[similar_posts_idxs]\n",
    "    # return the top 5 posts\n",
    "    return similar_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Input Post-----\n",
      "Former Navy Secretary Richard Spencer penned an op-ed in The Washington Post about his clashes with President Trump over the case of convicted war criminal Eddie Gallagher, which led to Spencer's resignation.\n",
      "\n",
      "-----Relevant Posts-----\n",
      "=> In his first interview since being ousted as Navy secretary, Richard Spencer told CBS that President Donald Trump's decision to block the Pentagon's review of convicted war criminal Eddie Gallagher sends a message \"that you can get away with things.\"\n",
      "=> Secretary of Defense Mark Esper has asked Navy Secretary Richard Spencer to resign over the demotion of a Navy SEAL convicted of war crimes.\n",
      "=> Recently ousted Navy Secretary Richard Spencer detailed President Trump's intervention in a war crimes case in a Washington Post op-ed, calling the President's actions \"shocking and unprecedented\"\n",
      "=> Recently ousted Navy Secretary Richard Spencer detailed President Trump's intervention in a war crimes case in a Washington Post op-ed Wednesday, calling the President's actions \"shocking and unprecedented\"\n",
      "=> President Trump has tapped Kenneth Braithwaite, his ambassador to Norway, to replace ousted Navy Secretary Richard Spencer amid tensions between top military leaders and the White House over a controversial case involving a Navy SEAL accused of war crimes\n"
     ]
    }
   ],
   "source": [
    "post_id = 10101\n",
    "\n",
    "print('-----Input Post-----')\n",
    "print((df.loc[df['rec_id'] == post_id]['text']).values[0])\n",
    "print('\\n-----Relevant Posts-----')\n",
    "for i in relevant_posts(postId = post_id, posts = posts_list, doc_sims = doc_sim_df):\n",
    "    print(\"=>\",(df.loc[df['rec_id'] == i]['text']).values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
